#### 一、NoSQL的简介

##### 1）简介

是非关系数据库，是对不同于传统的关系型数据库数据库管理系统的统称，

![1564105868763](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1564105868763.png)

##### 2）特点

1.不支持SQL语法

​        世界没有一中通用的语言，每种NoSQL都有自己的语法



2.读写性能高

​         NoSQL数据库都有非常高的读写性能，尤其在海量数据下

3.灵活的数据模型

​        NoSQL 的数据非常灵活，存储方式可以是JSON文档，键值对（key，values）或其他方式

```
Redis 一共有 2 种持久化方式，分别是 RDB 和 AOF，下面我来详细介绍两种方式在各个过程所做的事情，特点等等。


1. RDB 持久化


RDB 持久化是 Redis 默认的持久化方式。


它所生成的 RDB 文件是一个压缩的二进制文件，通过该文件可以还原生成 RDB 文件时的数据库状态


PS：数据库状态是指 Redis 服务器的非空数据库以及他们键值对的统称


1.1 RDB 文件的创建

有两个命令可以生成 RDB 文件，一个是 SAVE、另一个是 BGSAVE。


两者的区别在于：前者会阻塞 Redis 服务器进程，直到 RDB 文件创建完毕为止。  


而在服务器进程阻塞期间，服务器是不能处理任何命令请求的。


后者则不会阻塞服务器进程，因为是通过 fork 一个子进程，并让其去创建 RDB 文件，而服务器进程（父进程）继续则继续处理命令请求。


当写完数据库状态后，新 RDB 文件就会原子地替换旧的 RDB 文件。


此处小提问：如果在执行 BGSAVE 期间，客户端发送 SAVE、BGSAVE 或 BGREWRITEAOF 命令给服务端，服务端会如何处理呢？


答案：在执行 BGSAVE 期间，上述三个命令都不会被执行。    


详细原因：前两个会被直接拒绝，原因是为了避免父子进程同时执行两个 rdbSave 调用，防止产生竞争条件。  


而 BGREWRITEAOF 命令则是会被延迟到 BGSAVE 命令执行之后再执行。    


但如果是 BGREWRITEAOF 命令正在执行，此时客户端发送 BGSAVE 命令则会被拒绝。    


因为 BGREWRITEAOF 和 BGSAVE 都是由子进程执行的，所以在操作方面没有冲突的地方，不能同时执行的原因是性能上的考虑——并发出两个子进程，并且这两个子进程都会同时执行大量 io（磁盘写入）操作



1.2 RDB 文件的载入


RDB 文件的载入是在服务器启动时自动执行的，所以没有用于载入的命令，期间阻塞主进程。


只要没有开启 AOF 持久化功能，在启动时检测到有 RDB 文件，就会自动载入。


当服务器有开启 AOF 持久化功能时，服务器将会优先使用 AOF 文件来还原数据库状态。原因是 AOF 文件的更新频率通常比 RDB 文件的更新频率高。


1.3 自动间隔性保存 


对于 RDB 持久化而言，我们一般都会使用 BGSAVE 来持久化，毕竟它不会阻塞服务器进程。


在 Redis 的配置文件，有提供设置服务器每隔多久时间来执行 BGSAVE 命令。


Redis 默认是如下配置：  

save 900 1      // 900 秒内，对数据库至少修改 1 次。下面同理    

save 300 10     

save 60 10000       


只要满足其中一种情况，服务器就会执行 BGSAVE 命令。


2. AOF 持久化


我们从上面的介绍知道，RDB 持久化通过保存数据库状态来持久化。而 AOF 与之不同，它是通过保存对数据库的写命令来记录数据库状态。


比如执行了 set key 123,Redis 就会将这条写命令保存到 AOF 文件中。


在服务器下次启动时，就可以通过载入和执行 AOF 文件中保存的命令，来还原服务器关闭前的数据库状态了。


总体流程和 RDB 持久化一样 —— 都是创建一个 xxx 文件、在服务器下次启动时就载入这个文件来还原数据


那么，AOF 持久化具体是怎么实现的呢？


2.1 AOF 持久化实现


AOF 持久化功能的实现可以分为 3 个步骤：命令追加、文件写入、文件同步


其中命令追加很好理解，就是将写命令追加到 AOF 缓冲区的末尾。


那文件写入和文件同步怎么理解呢？刚开始我也一脸懵逼，终于在网上找到了答案，参考见文末，有兴趣的读者可以去看看。


先不卖关子了，简单一句话解释就是：前者是缓冲区内容写到 AOF 文件，后者是将 AOF 文件保存到磁盘。


ok，明白什么意思之后，我们稍微详细看下这两个东西是什么鬼。


在《Redis设计与实现》中提到，Redis 服务器进程就是一个事件循环，这个循环中的文件事件（socket 的可读可写事件）负责接收客户端的命令请求，以及向客户端发送命令结果。


因为服务器在处理文件事件时，可能会发生写操作，使得一些内容会被追加到 AOF 缓冲区末尾。所以，在服务器每次结束一个事件循环之前 ，都会调用 flushAppendOnlyFile 方法。


这个方法执行以下两个工作：


WRITE：根据条件，将缓冲区内容写入到 AOF 文件。

SAVE：根据条件，调用 fsync 或 fdatasync 函数，将 AOF 文件保存到磁盘中。


两个步骤都需要根据一定的条件来执行，而这些条件由 Redis 配置文件中的 appendfsync 选项来决定的，一共有三个选择：


1. appendfsync always：每执行一个命令保存一次

2. appendfsync everysec（默认，推荐）：每一秒钟保存一次

3. appendfsync no：不保存


下面说下三个的区别：


appendfsync always：每次执行完一个命令之后， WRITE 和 SAVE 都会被执行  

appendfsync everysec：SAVE 原则上每隔一秒钟就会执行一次。

appendfsync no：每次执行完一个命令之后， WRITE 会执行，SAVE 都会被忽略，只会在以下任意一种情况中被执行：

Redis 被关闭

AOF 功能被关闭

系统的写缓存被刷新（可能是缓存已经被写满，或者定期保存操作被执行。完成依赖 OS 的写入，一般为 30 秒左右一次）


而对于操作特性来分析的话，则是如下情况：

 


既然 AOF 持久化是通过保存写命令到文件的，那随着时间的推移，这个 AOF 文件记录的内容就越来越多，文件体积也就越来越大，对其进行数据还原的时间也就越来越久。


针对这个问题，Redis 提供了 AOF 文件重写功能。


2.2 AOF 重写


通过该功能来创建一个新的 AOF 文件来代替旧文件。并且两个文件所保存的数据库状态一样，但新文件不会包含任何冗余命令，所以新文件要比旧文件小得多。


而为什么新文件不会包含任何冗余命令呢？


那是因为这个重写功能是通过读取服务器当前的数据库状态来实现的。虽然叫做「重写」，但实际上并没有对旧文件进行任何读取修改。


比如旧文件保存了对某个 key 有 4 个 set 命令，经过重写之后，新文件只会记录最后一次对该 key 的 set 命令。因此说新文件不会包含任何冗余命令


因为重写涉及到大量 IO 操作，所以 Redis 是用子进程来实现这个功能的，否则将会阻塞主进程。该子进程拥有父进程的数据副本，可以避免在使用锁的情况下，保证数据的安全性。


那么这里又会存在一个问题，子进程在重写过程中，服务器还在继续处理命令请求，新命令可能会对数据库进行修改，这会导致当前数据库状态和重写后的 AOF 文件，所保存的数据库状态不一致。


为了解决这个问题，Redis 设置了一个 AOF 重写缓冲区。在子进程执行 AOF 重写期间，主进程需要执行以下三个步骤：


1. 执行客户端的请求命令

2. 将执行后的写命令追加到 AOF 缓冲区

3. 将执行后的写命令追加到 AOF 重写缓冲区


当子进程结束重写后，会向主进程发送一个信号，主进程接收到之后会调用信号处理函数执行以下步骤：


1. 将 AOF 重写缓冲区内容写入新的 AOF 文件中。此时新文件所保存的数据库状态就和当前数据库状态一致了

2. 对新文件进行改名，原子地覆盖现有 AOF 文件，完成新旧文件的替换。


当函数执行完成后，主进程就继续处理客户端命令。


因此，在整个 AOF 重写过程中，只有在执行信号处理函数时才会阻塞主进程，其他时候都不会阻塞。


3. 选择持久化方案的官方建议


到目前为止，Redis 的两种持久化方式就介绍得差不多了。可能你会有疑惑，在实际项目中，我到底要选择哪种持久化方案呢？下面，我贴下官方建议：


通常，如果你要想提供很高的数据保障性，那么建议你同时使用两种持久化方式。如果你可以接受灾难带来的几分钟的数据丢失，那么你可以仅使用 RDB。


很多用户仅使用了 AOF，但是我们建议，既然 RDB 可以时不时的给数据做个完整的快照，并且提供更快的重启，所以最好还是也使用 RDB。


在数据恢复方面：

    

RDB 的启动时间会更短，原因有两个：


1. RDB 文件中每一条数据只有一条记录，不会像 AOF 日志那样可能有一条数据的多次操作记录。所以每条数据只需要写一次就行了。

2. RDB 文件的存储格式和 Redis 数据在内存中的编码格式是一致的，不需要再进行数据编码工作，所以在 CPU 消耗上要远小于 AOF 日志的加载。  


注意：上面说了 RDB 快照的持久化，在进行快照的时候（save），fork 出来进行 dump 操作的子进程会占用与父进程一样的内存，真正的 copy-on-write，对性能的影响和内存的耗用都是比较大的。


比如机器 8G 内存，Redis 已经使用了 6G 内存，这时 save 的话会再生成 6G，变成 12G，大于系统的 8G。这时候会发生交换；要是虚拟内存不够则会崩溃，导致数据丢失。所以在用 redis 的时候一定对系统内存做好容量规划。    


目前，通常的设计思路是利用复制（Replication）机制来弥补 aof、snapshot 性能上的不足，达到了数据可持久化。即 Master 上 Snapshot 和 AOF 都不做，来保证 Master 的读写性能，而 Slave 上则同时开启 Snapshot 和 AOF 来进行持久化，保证数据的安全性。 


坦白讲，我也不知道有多少人能坚持看到这里，文章知识点有点干和杂，这里我帮大家简单总结一下，做个回顾：    


RDB 持久化是 Redis 默认持久化方式，通过保存数据库键值对来记录状态来持久化，由 SAVE 和 BGSAVE 命令来创建 RDB 文件。

```



#### 二、Redis简介

#### 1）简介

1.意大利人开发的一款高速缓存数据库，是一个高性能键值对（key，value）存储数据       全称：Remote Dictionary Server  （远程数据服务），使用C语言编写，并以内存作为数据存储介质，读写效率极高。

#### 2）特性

Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用

Redis不仅仅支持简单的key-value类型的数据，同时还把value分为list，set，zset，hash等数据结构存储。

因为Redis交换数据快，所以在服务器中常用来存储一些需要频繁调取的数据，提高效率。

#### 三、数据模型

##### 1）Redis数据结构

Redis是key和value的数据结构，每条数据都是一个键值对

 键的类型是字符串      注意：键不能重复     

值的类型分为五种：

1.String   ------>  字符串

2.Hash     ------>  哈希

3.List        ------>  列表

4.set         ------>  集合

5.Zset       ------>  有序集合

![1564107778680](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1564107778680.png)

##### 2）基本使用

1.连接redis：redis-cli

2.退出：exit

3.操作服务端：service redis start/stop/restart

4.切换数据库：select n

#### 四、五大数据类型

##### 1）String类型

1.设置数据：set  key  value

2.查看数据：get  key

3.追加数据：append  key  value

4.删除数据：del key;

##### 2)全局key操作

1.查看所有的key：keys *         exists key 查看key是否存在

2.删除键值对：del key   

3.改名：rename  key  new_key

4.设置过期时间：expire key seconds      ttl 查看时间    persist key  删除过期时间

##### 3)list的类型

1.list的类型是字符串列表，可以再列表头部或尾部添加/删除数据在插入数据时，如果键并不存在，Redis 将为该键创建一个新的

2.添加数据：rpush key value [value…]            lpush key value [value…]    ----  头部添加数据

3.查看数据：lrange key start stop               lindex key index（0开始）                  ----  查看某个数据

4.修改数据：lset key index value

5.删除数据：rpop key            lpop key                               ----  头部删除数据 

```
import redis
con = redis.StrictRedis(decode_responses=True)


# redis 命令
#（添加数据）
print(con.rpush('a', '刘安'))   #rpush
print(con.lpush('a', '周'))     #lpush

#（查看数据）
cha = con.lrange('a', 0, 10)    # 查看0-10的数据
print(cha)
cha = con.lindex('a',0)
print(cha)                      #查看第0填数据

#（修改数据）
print(con.lset('a', 3, '于'))    #将a中的第3条修改为于

#（删除数据）
print(con.lpop('a'))             #删除头部数据
print(con.rpop('a'))             #删除全部数据
```

```
import redis

class Redis_k:
     def __int__(self, ku, collection):
         self.con = redis.StrictRedis(decode_responses=True)      #建立连接
         self.ku = self.con[ku]
         self.coll = self.ku[collection]


     def my_rpush(self, data, flag=True):
         if flag:
             self.coll.rpush('a','刘邦')
         else:
             self.coll.lpush('a', '周瑜')

     def my_lrange(self, data, flag=True):
         if flag:
             print('查看全部数据：{}'.format(self.coll.lidex()))
         else:
             print('查询多条数据：{}')
             for i in self.coll.lrange():
                 print(i)

     def my_lset(self, data, query):
         self.coll.lset(data, query)

     def my_rpop(self, data, flag=True):
         if flag:
             self.coll.lpop('a')
         else:
             self.coll.rpop('a')


ma_data = [
    {'a', '许'},
    {'a', '高'},
    {'a', '值'},
    {'a', '看'}
]
print(ma_data)
```



##### 4）Hash类型

1.是一个键值（key--》value）对集合，是string类型的field 和 value映射表。

```
user                              { name:juhao，                       age:18 }

user  key(键)     name,age field(域)    juhao,18 value(值
```

2.添加数据：hset key field value

3.查看域值：hget key field             hgetall key  ----  查看所有的field和value

4.查看所有的value：hvals key

5.查看所有的field：hkeys key

##### 5）set类型

1.为无序的字符集合，元素具有唯一性，不重复。

2.添加数据：sadd key member [member …]

3.查看数据：smembers key

4.随机删除：spop key

5.指定删除：srem key member(value) [member …]

##### 6.Sorted Set类型

1.每个成员都会有一个分数（score）与之关联，成员是唯一，但分数可以重复

2.添加数据： zadd key score member [score2 member2 …]（1，kk）

3.查看数据： zrange key start stop       zrangebyscore key min max  -- 通过scores值查看

4.删除数据：zrem key member [member …]

5.通过索引删除多个数据：zremrangebyrank key min max              zremrangebyscore key min max  -- 通过scores值删除
